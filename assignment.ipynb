{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. What is hypothesis testing in statistics?\n",
    "\n",
    "Hypothesis testing is a statistical method used to determine whether there is enough evidence in a sample to infer a conclusion about a population.\n",
    "\n",
    "2.What is the null hypothesis, and how does it differ from the alternative hypothesis?\n",
    "\n",
    "\n",
    "The null hypothesis (Hâ‚€) states that there is no effect or difference (e.g., \"There is no difference between the means of two groups\").\n",
    "The alternative hypothesis (Hâ‚ or Ha) states that there is an effect or difference (e.g., \"There is a significant difference between the means of two groups\").\n",
    "\n",
    "3.What is the significance level in hypothesis testing, and why is it important?\n",
    "\n",
    "The significance level (Î±) is the probability of rejecting the null hypothesis when it is actually true. It is important because it helps control the likelihood of making a Type I error (false positive). A common value for Î± is 0.05 (5%).\n",
    "\n",
    "4.What does a P-value represent in hypothesis testing?\n",
    "\n",
    "The P-value measures the probability of obtaining results at least as extreme as the observed data, assuming the null hypothesis is true.\n",
    "\n",
    "5.How do you interpret the P-value in hypothesis testing?\n",
    "\n",
    "\n",
    "If P-value â‰¤ Î±: Reject the null hypothesis (strong evidence against Hâ‚€).\n",
    "If P-value > Î±: Fail to reject the null hypothesis (insufficient evidence to conclude Hâ‚ is true).\n",
    "\n",
    "6.What are Type 1 and Type 2 errors in hypothesis testing?\n",
    "\n",
    "\n",
    "Type I error (False Positive): Rejecting Hâ‚€ when it is actually true.\n",
    "Type II error (False Negative): Failing to reject Hâ‚€ when Hâ‚ is actually true.\n",
    "\n",
    "\n",
    "7.What is the difference between a one-tailed and a two-tailed test in hypothesis testing?\n",
    "\n",
    "\n",
    "One-tailed test: Tests if a parameter is significantly greater or less than a certain value.\n",
    "Two-tailed test: Tests for any significant difference in either direction.\n",
    "\n",
    "\n",
    "8.What is the Z-test, and when is it used in hypothesis testing?\n",
    "\n",
    "The Z-test is used when comparing population means, assuming a normal distribution and known population variance.\n",
    "\n",
    "9.How do you calculate the Z-score, and what does it represent in hypothesis testing?\n",
    "\n",
    "ğ‘\n",
    "=\n",
    "(\n",
    "ğ‘‹\n",
    "âˆ’\n",
    "ğœ‡\n",
    ")\n",
    "ğœ\n",
    "Z= \n",
    "Ïƒ\n",
    "(Xâˆ’Î¼)\n",
    "â€‹\n",
    " \n",
    "It represents the number of standard deviations a data point is from the mean.\n",
    "\n",
    "10.What is the T-distribution, and when should it be used instead of the normal distribution?\n",
    "\n",
    "The T-distribution is used when the sample size is small (n < 30) and/or the population variance is unknown.\n",
    "\n",
    "11.What is the difference between a Z-test and a T-test?\n",
    "\n",
    "Z-test: Used when population variance is known and sample size is large.\n",
    "T-test: Used when population variance is unknown and sample size is small.\n",
    "\n",
    "12.What is the T-test, and how is it used in hypothesis testing?\n",
    "\n",
    "The T-test is used to compare the means of two groups to determine if they are significantly different.\n",
    "\n",
    "13.What is the relationship between Z-test and T-test in hypothesis testing?\n",
    "\n",
    "The T-test is a generalized version of the Z-test, used when the population variance is unknown.\n",
    "\n",
    "14.What is a confidence interval, and how is it used to interpret statistical results?\n",
    "\n",
    "A confidence interval gives a range of values within which a population parameter is expected to lie, with a certain level of confidence (e.g., 95%).\n",
    "\n",
    "15.What is the margin of error, and how does it affect the confidence interval?\n",
    "\n",
    "The margin of error represents the range within which the true population parameter is expected to fall. A larger margin means less precision.\n",
    "\n",
    "16. How is Bayes' Theorem used in statistics, and what is its significance?\n",
    "\n",
    "Bayes' Theorem is used to update probabilities based on new evidence. It is significant in Bayesian inference and decision-making.\n",
    "\n",
    "17.What is the Chi-square distribution, and when is it used?\n",
    "\n",
    "The Chi-square distribution is used for categorical data analysis, such as goodness-of-fit and independence tests.\n",
    "\n",
    "18.What is the Chi-square goodness of fit test, and how is it applied?\n",
    "\n",
    "It tests whether an observed distribution fits an expected distribution.\n",
    "\n",
    "19.What is the F-distribution, and when is it used in hypothesis testing?\n",
    "\n",
    "The F-distribution is used in analysis of variance (ANOVA) and comparing variances.\n",
    "\n",
    "20.What is an ANOVA test, and what are its assumptions?\n",
    "\n",
    "ANOVA (Analysis of Variance) is used to compare the means of three or more groups. Assumptions include normality, independence, and equal variances.\n",
    "\n",
    "21.What are the different types of ANOVA tests?\n",
    "\n",
    "\n",
    "One-way ANOVA (single factor)\n",
    "Two-way ANOVA (two factors)\n",
    "Repeated measures ANOVA\n",
    "\n",
    "22.What is the F-test, and how does it relate to hypothesis testing?\n",
    "\n",
    "The F-test is used to compare variances or test multiple group means (ANOVA). It determines if groups have significantly different variances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#1.Perform a Z-test for comparing a sample mean to a known population mean\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "def z_test(sample, population_mean, population_std):\n",
    "    sample_mean = np.mean(sample)\n",
    "    sample_size = len(sample)\n",
    "    z_score = (sample_mean - population_mean) / (population_std / np.sqrt(sample_size))\n",
    "    p_value = 2 * (1 - stats.norm.cdf(abs(z_score)))  # Two-tailed test\n",
    "    \n",
    "    print(f\"Z-score: {z_score:.4f}\")\n",
    "    print(f\"P-value: {p_value:.4f}\")\n",
    "\n",
    "    if p_value < 0.05:\n",
    "        print(\"Reject the null hypothesis (significant difference).\")\n",
    "    else:\n",
    "        print(\"Fail to reject the null hypothesis (no significant difference).\")\n",
    "\n",
    "# Example usage\n",
    "np.random.seed(42)\n",
    "sample_data = np.random.normal(100, 15, 30)  # Sample data\n",
    "z_test(sample_data, population_mean=105, population_std=15)\n",
    "\n",
    "\n",
    "#2. Simulate random data for hypothesis testing and calculate the P-value\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import ttest_1samp\n",
    "\n",
    "# Simulating data\n",
    "np.random.seed(42)\n",
    "sample_data = np.random.normal(loc=100, scale=15, size=30)\n",
    "\n",
    "# Performing a one-sample T-test\n",
    "t_stat, p_value = ttest_1samp(sample_data, popmean=105)\n",
    "\n",
    "print(f\"T-statistic: {t_stat:.4f}\")\n",
    "print(f\"P-value: {p_value:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "#3. Implement a one-sample Z-test\n",
    "\n",
    "\n",
    "from statsmodels.stats.weightstats import ztest\n",
    "\n",
    "def one_sample_z_test(sample, population_mean):\n",
    "    z_stat, p_value = ztest(sample, value=population_mean)\n",
    "    print(f\"Z-statistic: {z_stat:.4f}\")\n",
    "    print(f\"P-value: {p_value:.4f}\")\n",
    "    \n",
    "    if p_value < 0.05:\n",
    "        print(\"Reject the null hypothesis.\")\n",
    "    else:\n",
    "        print(\"Fail to reject the null hypothesis.\")\n",
    "\n",
    "# Example usage\n",
    "np.random.seed(42)\n",
    "sample = np.random.normal(100, 15, 30)\n",
    "one_sample_z_test(sample, 105)\n",
    "\n",
    "\n",
    "\n",
    "#4. Perform a two-tailed Z-test and visualize decision region\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "\n",
    "# Z-test function\n",
    "def two_tailed_z_test(sample, pop_mean, pop_std):\n",
    "    sample_mean = np.mean(sample)\n",
    "    sample_size = len(sample)\n",
    "    z_score = (sample_mean - pop_mean) / (pop_std / np.sqrt(sample_size))\n",
    "    p_value = 2 * (1 - norm.cdf(abs(z_score)))\n",
    "\n",
    "    # Plot decision regions\n",
    "    x = np.linspace(-4, 4, 1000)\n",
    "    y = norm.pdf(x)\n",
    "\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(x, y, label=\"Standard Normal Distribution\")\n",
    "    plt.axvline(-1.96, color='r', linestyle='dashed', label=\"Critical value (-1.96)\")\n",
    "    plt.axvline(1.96, color='r', linestyle='dashed', label=\"Critical value (1.96)\")\n",
    "    plt.fill_between(x, y, where=(x < -1.96) | (x > 1.96), color='red', alpha=0.3)\n",
    "    plt.axvline(z_score, color='blue', linestyle='solid', label=f\"Z-score ({z_score:.2f})\")\n",
    "    plt.legend()\n",
    "    plt.title(\"Two-Tailed Z-Test Decision Region\")\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"Z-score: {z_score:.4f}, P-value: {p_value:.4f}\")\n",
    "    if p_value < 0.05:\n",
    "        print(\"Reject the null hypothesis.\")\n",
    "    else:\n",
    "        print(\"Fail to reject the null hypothesis.\")\n",
    "\n",
    "# Example usage\n",
    "np.random.seed(42)\n",
    "sample_data = np.random.normal(100, 15, 30)\n",
    "two_tailed_z_test(sample_data, 105, 15)\n",
    "\n",
    "\n",
    "\n",
    "#5. Visualizing Type 1 and Type 2 errors\n",
    "\n",
    "\n",
    "\n",
    "def plot_type1_type2():\n",
    "    x = np.linspace(-4, 4, 1000)\n",
    "    y = norm.pdf(x)\n",
    "\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(x, y, label=\"Standard Normal Distribution\")\n",
    "    plt.fill_between(x, y, where=(x < -1.96) | (x > 1.96), color='red', alpha=0.3, label=\"Type I Error (Î±)\")\n",
    "    plt.fill_between(x, y, where=(-1.28 < x) & (x < 1.28), color='blue', alpha=0.3, label=\"Type II Error (Î²)\")\n",
    "    \n",
    "    plt.axvline(-1.96, color='r', linestyle='dashed')\n",
    "    plt.axvline(1.96, color='r', linestyle='dashed')\n",
    "    plt.legend()\n",
    "    plt.title(\"Type I and Type II Errors in Hypothesis Testing\")\n",
    "    plt.show()\n",
    "\n",
    "plot_type1_type2()\n",
    "\n",
    "\n",
    "\n",
    "#6. Perform an independent T-test\n",
    "\n",
    "\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "np.random.seed(42)\n",
    "group1 = np.random.normal(100, 15, 30)\n",
    "group2 = np.random.normal(105, 15, 30)\n",
    "\n",
    "t_stat, p_value = ttest_ind(group1, group2)\n",
    "print(f\"T-statistic: {t_stat:.4f}, P-value: {p_value:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "#7. Perform a paired T-test\n",
    "\n",
    "\n",
    "\n",
    "from scipy.stats import ttest_rel\n",
    "\n",
    "# Simulating before and after treatment data\n",
    "np.random.seed(42)\n",
    "before = np.random.normal(100, 15, 30)\n",
    "after = before + np.random.normal(2, 5, 30)\n",
    "\n",
    "t_stat, p_value = ttest_rel(before, after)\n",
    "print(f\"T-statistic: {t_stat:.4f}, P-value: {p_value:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "#8. Simulate data and compare Z-test and T-test results\n",
    "\n",
    "\n",
    "np.random.seed(42)\n",
    "sample = np.random.normal(100, 15, 30)\n",
    "\n",
    "z_stat, z_p = ztest(sample, value=105)\n",
    "t_stat, t_p = ttest_1samp(sample, 105)\n",
    "\n",
    "print(f\"Z-test: Z-stat={z_stat:.4f}, P-value={z_p:.4f}\")\n",
    "print(f\"T-test: T-stat={t_stat:.4f}, P-value={t_p:.4f}\")\n",
    "\n",
    "\n",
    "#9. Calculate and interpret a confidence interval\n",
    "\n",
    "\n",
    "def confidence_interval(sample, confidence=0.95):\n",
    "    sample_mean = np.mean(sample)\n",
    "    sample_std = np.std(sample, ddof=1)\n",
    "    n = len(sample)\n",
    "    margin_error = stats.t.ppf((1 + confidence) / 2, df=n-1) * (sample_std / np.sqrt(n))\n",
    "\n",
    "    lower_bound = sample_mean - margin_error\n",
    "    upper_bound = sample_mean + margin_error\n",
    "\n",
    "    print(f\"{confidence*100}% Confidence Interval: ({lower_bound:.2f}, {upper_bound:.2f})\")\n",
    "    return lower_bound, upper_bound\n",
    "\n",
    "# Example usage\n",
    "np.random.seed(42)\n",
    "sample = np.random.normal(100, 15, 30)\n",
    "confidence_interval(sample)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#10. Calculate the Margin of Error for a Given Confidence Level\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import t\n",
    "\n",
    "def margin_of_error(sample, confidence=0.95):\n",
    "    sample_mean = np.mean(sample)\n",
    "    sample_std = np.std(sample, ddof=1)\n",
    "    n = len(sample)\n",
    "    t_critical = t.ppf((1 + confidence) / 2, df=n-1)  # t-critical value\n",
    "    margin_error = t_critical * (sample_std / np.sqrt(n))\n",
    "\n",
    "    print(f\"Margin of Error: {margin_error:.4f}\")\n",
    "    return margin_error\n",
    "\n",
    "# Example usage\n",
    "np.random.seed(42)\n",
    "sample_data = np.random.normal(100, 15, 30)\n",
    "margin_of_error(sample_data)\n",
    "\n",
    "\n",
    "\n",
    "#11. Bayesian Inference using Bayes' Theorem\n",
    "\n",
    "\n",
    "\n",
    "def bayes_theorem(prior, likelihood, evidence):\n",
    "    posterior = (likelihood * prior) / evidence\n",
    "    return posterior\n",
    "\n",
    "# Example: Disease Testing\n",
    "prior = 0.01  # Probability of having a disease\n",
    "likelihood = 0.95  # Sensitivity of test (true positive rate)\n",
    "false_positive_rate = 0.05  # Probability of false positive\n",
    "evidence = (likelihood * prior) + (false_positive_rate * (1 - prior))\n",
    "\n",
    "posterior = bayes_theorem(prior, likelihood, evidence)\n",
    "print(f\"Posterior probability of having the disease given a positive test: {posterior:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "#12. Chi-Square Test for Independence\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Simulated contingency table (2x2)\n",
    "data = np.array([[50, 30], [20, 40]])\n",
    "chi2_stat, p, dof, expected = stats.chi2_contingency(data)\n",
    "\n",
    "print(f\"Chi-Square Statistic: {chi2_stat:.4f}\")\n",
    "print(f\"P-value: {p:.4f}\")\n",
    "print(f\"Degrees of Freedom: {dof}\")\n",
    "print(\"Expected Frequencies:\")\n",
    "print(expected)\n",
    "\n",
    "\n",
    "\n",
    "#13. Expected Frequencies for Chi-Square Test\n",
    "\n",
    "\n",
    "def expected_frequencies(observed):\n",
    "    _, _, _, expected = stats.chi2_contingency(observed)\n",
    "    return expected\n",
    "\n",
    "observed_data = np.array([[50, 30], [20, 40]])\n",
    "expected_freqs = expected_frequencies(observed_data)\n",
    "print(\"Expected Frequencies:\\n\", expected_freqs)\n",
    "\n",
    "\n",
    "\n",
    "#14. Goodness-of-Fit Test\n",
    "\n",
    "observed = np.array([50, 30, 20])\n",
    "expected = np.array([40, 40, 20])\n",
    "chi2_stat, p = stats.chisquare(observed, expected)\n",
    "\n",
    "print(f\"Chi-Square Statistic: {chi2_stat:.4f}\")\n",
    "print(f\"P-value: {p:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "#15. Simulate and Visualize the Chi-Square Distribution\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "\n",
    "df = 4  # Degrees of freedom\n",
    "x = np.linspace(0, 20, 100)\n",
    "y = stats.chi2.pdf(x, df)\n",
    "\n",
    "plt.plot(x, y, label=f\"Chi-Square Distribution (df={df})\")\n",
    "plt.fill_between(x, y, alpha=0.3)\n",
    "plt.title(\"Chi-Square Distribution\")\n",
    "plt.xlabel(\"Value\")\n",
    "plt.ylabel(\"Probability Density\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "#16. F-Test to Compare Variances\n",
    "\n",
    "\n",
    "\n",
    "def f_test(sample1, sample2):\n",
    "    var1, var2 = np.var(sample1, ddof=1), np.var(sample2, ddof=1)\n",
    "    f_stat = var1 / var2\n",
    "    df1, df2 = len(sample1)-1, len(sample2)-1\n",
    "    p_value = 1 - stats.f.cdf(f_stat, df1, df2)\n",
    "\n",
    "    print(f\"F-Statistic: {f_stat:.4f}\")\n",
    "    print(f\"P-value: {p_value:.4f}\")\n",
    "\n",
    "np.random.seed(42)\n",
    "data1 = np.random.normal(100, 15, 30)\n",
    "data2 = np.random.normal(105, 10, 30)\n",
    "f_test(data1, data2)\n",
    "\n",
    "\n",
    "\n",
    "#17. One-Way ANOVA\n",
    "\n",
    "\n",
    "from scipy.stats import f_oneway\n",
    "\n",
    "np.random.seed(42)\n",
    "group1 = np.random.normal(100, 15, 30)\n",
    "group2 = np.random.normal(105, 15, 30)\n",
    "group3 = np.random.normal(110, 15, 30)\n",
    "\n",
    "f_stat, p_value = f_oneway(group1, group2, group3)\n",
    "print(f\"F-Statistic: {f_stat:.4f}, P-value: {p_value:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "#18. Check ANOVA Assumptions\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "def check_anova_assumptions(data):\n",
    "    # Normality check\n",
    "    sm.qqplot(data, line='s')\n",
    "    plt.title(\"Q-Q Plot for Normality Check\")\n",
    "    plt.show()\n",
    "\n",
    "    # Histogram\n",
    "    sns.histplot(data, kde=True)\n",
    "    plt.title(\"Histogram for Normality Check\")\n",
    "    plt.show()\n",
    "\n",
    "    # Variance check\n",
    "    print(\"Variance:\", np.var(data, ddof=1))\n",
    "\n",
    "np.random.seed(42)\n",
    "sample_data = np.random.normal(100, 15, 30)\n",
    "check_anova_assumptions(sample_data)\n",
    "\n",
    "\n",
    "\n",
    "#19. Two-Way ANOVA\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Simulated dataset\n",
    "df = pd.DataFrame({\n",
    "    \"Factor1\": np.repeat([\"A\", \"B\"], 30),\n",
    "    \"Factor2\": np.tile([\"X\", \"Y\"], 30),\n",
    "    \"Values\": np.random.normal(100, 15, 60)\n",
    "})\n",
    "\n",
    "# Two-way ANOVA\n",
    "model = ols('Values ~ C(Factor1) + C(Factor2) + C(Factor1):C(Factor2)', data=df).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "print(anova_table)\n",
    "\n",
    "\n",
    "\n",
    "#20. Visualizing F-Distribution\n",
    "\n",
    "\n",
    "\n",
    "df1, df2 = 10, 20\n",
    "x = np.linspace(0, 5, 100)\n",
    "y = stats.f.pdf(x, df1, df2)\n",
    "\n",
    "plt.plot(x, y, label=f\"F-distribution (df1={df1}, df2={df2})\")\n",
    "plt.fill_between(x, y, alpha=0.3)\n",
    "plt.title(\"F-Distribution\")\n",
    "plt.xlabel(\"F-value\")\n",
    "plt.ylabel(\"Probability Density\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "#21. Z-Test for Proportions\n",
    "\n",
    "\n",
    "\n",
    "from statsmodels.stats.proportion import proportions_ztest\n",
    "\n",
    "successes = np.array([40, 50])\n",
    "samples = np.array([100, 120])\n",
    "\n",
    "z_stat, p_value = proportions_ztest(successes, samples)\n",
    "print(f\"Z-Statistic: {z_stat:.4f}, P-value: {p_value:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "#22. Chi-Square Goodness-of-Fit Test with Simulated Data\n",
    "\n",
    "\n",
    "observed = np.random.randint(20, 50, size=5)\n",
    "expected = np.full(5, np.mean(observed))\n",
    "chi2_stat, p_value = stats.chisquare(observed, expected)\n",
    "\n",
    "print(f\"Chi-Square Statistic: {chi2_stat:.4f}, P-value: {p_value:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
